{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "import statistics \n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import statistics\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Convolution Neural Networks(CNN)\n",
    "3. Long Short term Memory Networks(LSTM)\n",
    "\n",
    "Among three Logistic Regression showed better results of Accuracy on validation data\n",
    "\n",
    "1.Logistic Regression:\n",
    "\n",
    "Results are as follows:\n",
    "\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
    "\n",
    "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  1.7min finished\n",
    "\n",
    "Validation Accuracy: 0.6883942766295708\n",
    "\n",
    "2.Convolution Neural Networks(CNN):\n",
    "epochs : 5\n",
    "\n",
    "Time taken:3.2 mins\n",
    "\n",
    "Validation Accuracy: 0.6455\n",
    "\n",
    "3.LSTM:\n",
    "epochs: 6\n",
    "\n",
    "Time taken:2.4 mins\n",
    "\n",
    "Validation Accuracy: 0.6383\n",
    "\n",
    "Cross Validation:\n",
    "\n",
    "Performed cross validation using GridSearchCV on Logistic Regression\n",
    "1. using array of values of 'C' (smaller the values of C better are the results), \n",
    "C = 10 showed a good improvement in model, further increase in C reduced the accuracy.\n",
    "\n",
    "2. class_weight as Balanced\n",
    "\n",
    "3. used tolerance which gave a signifinantly low accuracy so took a single value of 0.01 (tol: max value = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/PHD\")\n",
    "%run Library_list.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6287, 6)\n",
      "Index(['Reviewid', 'Hotelid', 'userid', 'Date', 'reviewtext', 'Sentiment'], dtype='object')\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Hotelid</th>\n",
       "      <th>userid</th>\n",
       "      <th>Date</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review_1</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_1608</td>\n",
       "      <td>16-Nov-07</td>\n",
       "      <td>Nice Marriot       View of my king bed room</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review_2</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_6939</td>\n",
       "      <td>30-Oct-07</td>\n",
       "      <td>Good hotel, charges for internet access The Ma...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review_3</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_3976</td>\n",
       "      <td>12-Oct-07</td>\n",
       "      <td>Small but adequate rooms If you have an early ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review_4</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_2851</td>\n",
       "      <td>31-Aug-07</td>\n",
       "      <td>Better than average, some noisy rooms I have s...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review_5</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7897</td>\n",
       "      <td>18-Jul-07</td>\n",
       "      <td>Ordinary Although it is highly rated in these ...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reviewid    Hotelid      userid       Date  \\\n",
       "0  Review_1  hotel_101  hotel_1608  16-Nov-07   \n",
       "1  Review_2  hotel_101  hotel_6939  30-Oct-07   \n",
       "2  Review_3  hotel_101  hotel_3976  12-Oct-07   \n",
       "3  Review_4  hotel_101  hotel_2851  31-Aug-07   \n",
       "4  Review_5  hotel_101  hotel_7897  18-Jul-07   \n",
       "\n",
       "                                          reviewtext Sentiment  \n",
       "0        Nice Marriot       View of my king bed room      good  \n",
       "1  Good hotel, charges for internet access The Ma...      good  \n",
       "2  Small but adequate rooms If you have an early ...      good  \n",
       "3  Better than average, some noisy rooms I have s...      good  \n",
       "4  Ordinary Although it is highly rated in these ...       bad  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = pd.read_csv(\"Train-1554810061973.csv\",encoding='latin-1')\n",
    "print(trainData.shape) # Print the dimensions of train DataFrame\n",
    "print(trainData.columns) # Print the column names of the DataFrame\n",
    "print('\\n')\n",
    "trainData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3468, 5)\n",
      "Index(['Reviewid', 'Hotelid', 'userid', 'Date', 'reviewtext'], dtype='object')\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Hotelid</th>\n",
       "      <th>userid</th>\n",
       "      <th>Date</th>\n",
       "      <th>reviewtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review_11001</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_2225</td>\n",
       "      <td>Dec 13, 2008</td>\n",
       "      <td>Just An Average stay This was just an average ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review_11002</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5079</td>\n",
       "      <td>Dec 2, 2008</td>\n",
       "      <td>go elsewhere The place is hugely overpriced an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review_11003</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_8440</td>\n",
       "      <td>Nov 18, 2008</td>\n",
       "      <td>I Won't Go Back I stayed at the hotel 11/14/08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review_11004</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_4592</td>\n",
       "      <td>Oct 19, 2008</td>\n",
       "      <td>Good weekend stay My wife and I stay here quit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review_11005</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5901</td>\n",
       "      <td>Oct 13, 2008</td>\n",
       "      <td>Great airport stay Lovely indoor pool area, lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reviewid    Hotelid      userid          Date  \\\n",
       "0  Review_11001  hotel_101  hotel_2225  Dec 13, 2008   \n",
       "1  Review_11002  hotel_101  hotel_5079   Dec 2, 2008   \n",
       "2  Review_11003  hotel_101  hotel_8440  Nov 18, 2008   \n",
       "3  Review_11004  hotel_101  hotel_4592  Oct 19, 2008   \n",
       "4  Review_11005  hotel_101  hotel_5901  Oct 13, 2008   \n",
       "\n",
       "                                          reviewtext  \n",
       "0  Just An Average stay This was just an average ...  \n",
       "1  go elsewhere The place is hugely overpriced an...  \n",
       "2  I Won't Go Back I stayed at the hotel 11/14/08...  \n",
       "3  Good weekend stay My wife and I stay here quit...  \n",
       "4  Great airport stay Lovely indoor pool area, lo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = pd.read_csv(\"Test-1555730055539.csv\",encoding='latin-1')\n",
    "print(testData.shape) # Print the dimensions of train DataFrame\n",
    "print(testData.columns) # Print the column names of the DataFrame\n",
    "print('\\n')\n",
    "testData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewId = trainData['Reviewid']\n",
    "reviewId_Test = testData['Reviewid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Hotelid</th>\n",
       "      <th>userid</th>\n",
       "      <th>Date</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review_1</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_1608</td>\n",
       "      <td>16-Nov-07</td>\n",
       "      <td>Nice Marriot       View of my king bed room</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review_2</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_6939</td>\n",
       "      <td>30-Oct-07</td>\n",
       "      <td>Good hotel, charges for internet access The Ma...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review_3</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_3976</td>\n",
       "      <td>12-Oct-07</td>\n",
       "      <td>Small but adequate rooms If you have an early ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review_4</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_2851</td>\n",
       "      <td>31-Aug-07</td>\n",
       "      <td>Better than average, some noisy rooms I have s...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review_5</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7897</td>\n",
       "      <td>18-Jul-07</td>\n",
       "      <td>Ordinary Although it is highly rated in these ...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Review_6</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_3297</td>\n",
       "      <td>13-Jul-07</td>\n",
       "      <td>Awesome for early AM flight Wow! what a supris...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Review_7</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5463</td>\n",
       "      <td>4-Jul-07</td>\n",
       "      <td>Good Stay Spent two nights there in Jun. The h...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Review_8</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_9766</td>\n",
       "      <td>14-Jun-07</td>\n",
       "      <td>Great Staff We stayed overnight the last week ...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Review_9</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7042</td>\n",
       "      <td>13-Jun-07</td>\n",
       "      <td>fine choice for seatac The lobby is attractive...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Review_10</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_9805</td>\n",
       "      <td>30-May-07</td>\n",
       "      <td>Great value, looking for a nice hotel. not exp...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Reviewid    Hotelid      userid       Date  \\\n",
       "0   Review_1  hotel_101  hotel_1608  16-Nov-07   \n",
       "1   Review_2  hotel_101  hotel_6939  30-Oct-07   \n",
       "2   Review_3  hotel_101  hotel_3976  12-Oct-07   \n",
       "3   Review_4  hotel_101  hotel_2851  31-Aug-07   \n",
       "4   Review_5  hotel_101  hotel_7897  18-Jul-07   \n",
       "5   Review_6  hotel_101  hotel_3297  13-Jul-07   \n",
       "6   Review_7  hotel_101  hotel_5463   4-Jul-07   \n",
       "7   Review_8  hotel_101  hotel_9766  14-Jun-07   \n",
       "8   Review_9  hotel_101  hotel_7042  13-Jun-07   \n",
       "9  Review_10  hotel_101  hotel_9805  30-May-07   \n",
       "\n",
       "                                          reviewtext  Sentiment  \n",
       "0        Nice Marriot       View of my king bed room       good  \n",
       "1  Good hotel, charges for internet access The Ma...       good  \n",
       "2  Small but adequate rooms If you have an early ...       good  \n",
       "3  Better than average, some noisy rooms I have s...       good  \n",
       "4  Ordinary Although it is highly rated in these ...        bad  \n",
       "5  Awesome for early AM flight Wow! what a supris...  excellent  \n",
       "6  Good Stay Spent two nights there in Jun. The h...       good  \n",
       "7  Great Staff We stayed overnight the last week ...  excellent  \n",
       "8  fine choice for seatac The lobby is attractive...       good  \n",
       "9  Great value, looking for a nice hotel. not exp...       good  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews =trainData.reviewtext.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = testData.reviewtext.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_test = word_tokenize(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36289\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(tokens)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24936\n"
     ]
    }
   ],
   "source": [
    "vocabulary_test = set(tokens_test)\n",
    "print(len(vocabulary_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [w for w in tokens if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_test = set(stopwords.words('english'))\n",
    "tokens_test_1 = [w for w in tokens_test if not w in stop_words_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CBPLDEV11\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_words = 200 # setting input shape\n",
    "seq_len = 200\n",
    "embedding_size = 100\n",
    "\n",
    "data=trainData.loc[:,[\"reviewtext\",\"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom function for Text clean up.\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(text): #clean text\n",
    "    # #     text = text.translate()\n",
    "    text=text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"what'd\", \"what would \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\' +\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    chars = re.escape(string.punctuation)\n",
    "    text=re.sub(r'['+chars+']',\"\",text)\n",
    "    \n",
    "    text=text.split()\n",
    "    stops=set(stopwords.words(\"english\"))\n",
    "    text = [x for x in text if x not in stops]\n",
    "    \n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice Marriot       View of my king bed room</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    reviewtext Sentiment\n",
       "0  Nice Marriot       View of my king bed room      good"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying custom function for text clean up on train data\n",
    "data['reviewtext'] = data['reviewtext'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice marriot view king bed room</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good hotel charge internet access marriott air...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small adequate room early morning flight catch...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good average noisy room stay hotel time inthe ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ordinary although highly rat reviews pay premi...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>awesome early flight wow suprise stay property...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good stay spend two night jun hotel close airp...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>great staff stay overnight last week may fly m...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fine choice seatac lobby attractive bit small ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>great value look nice hotel expensive nice ser...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewtext  Sentiment\n",
       "0                    nice marriot view king bed room       good\n",
       "1  good hotel charge internet access marriott air...       good\n",
       "2  small adequate room early morning flight catch...       good\n",
       "3  good average noisy room stay hotel time inthe ...       good\n",
       "4  ordinary although highly rat reviews pay premi...        bad\n",
       "5  awesome early flight wow suprise stay property...  excellent\n",
       "6  good stay spend two night jun hotel close airp...       good\n",
       "7  great staff stay overnight last week may fly m...  excellent\n",
       "8  fine choice seatac lobby attractive bit small ...       good\n",
       "9  great value look nice hotel expensive nice ser...       good"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying custom function for text clean up on test data\n",
    "testData['reviewtext'] = testData['reviewtext'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'excellent' 'good']\n",
      "[1103 1971 3213]\n"
     ]
    }
   ],
   "source": [
    "# Print the unique classes and their counts/frequencies\n",
    "classes = np.unique(data['Sentiment'], return_counts=True) # np.unique returns a tuple with class names and counts\n",
    "print(classes[0]) #Print the list of unique classes\n",
    "print(classes[1]) #Print the list of frequencies of the above classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target and Predictor \n",
    "y=data.drop(columns='reviewtext', axis = 1)\n",
    "X=data.drop(columns=\"Sentiment\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train and Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    data['reviewtext'], data['Sentiment'], random_state=3422, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5029,)\n",
      "(5029,)\n",
      "(1258,)\n",
      "(1258,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5029, 22872)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "#Lets construct TF-idf matrix based on the train documents\n",
    "tfidf_transformer = TfidfVectorizer(ngram_range=(1,1),stop_words='english',lowercase = True)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_Train_Dense = X_train_tfidf.todense()\n",
    "X_Train_tf=pd.DataFrame(X_Train_Dense)\n",
    "X_Train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3468, 22872)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unseen_test_data_tfidf = tfidf_transformer.transform(testData['reviewtext'])\n",
    "X_unseen_test_dense = X_unseen_test_data_tfidf.todense()\n",
    "X_unseen_tf=pd.DataFrame(X_unseen_test_dense)\n",
    "X_unseen_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5029, 22872)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tfidf = tfidf_transformer.transform(y_train)\n",
    "y_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 22872)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the tfidf matrix for test documents\n",
    "X_val_tfidf = tfidf_transformer.transform(X_test)\n",
    "X_val_dense = X_val_tfidf.todense()\n",
    "X_val_tf = pd.DataFrame(X_val_dense)\n",
    "X_val_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3468, 22872), (1258, 22872))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unseen_tf.shape, X_val_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CBPLDEV11\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\Users\\CBPLDEV11\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good' 'bad' 'bad' ... 'bad' 'good' 'excellent']\n",
      "Train_Confusion matrix:\n",
      " [[139   4  62]\n",
      " [  7 234 173]\n",
      " [ 35 129 475]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6740858505564388"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logreg_train = LogisticRegression(C= 10, tol = 0.01)\n",
    "\n",
    "lr_clf = logreg_train.fit(X_Train_tf, y_train)\n",
    "\n",
    "pred_lr_train=lr_clf.predict(X_Train_tf) # predict on train data\n",
    "pred_lr_val = lr_clf.predict(X_val_tf)\n",
    "\n",
    "pred_lr_test = lr_clf.predict(X_unseen_tf)\n",
    "\n",
    "print(pred_lr_test)\n",
    "print(\"Train_Confusion matrix:\\n\", confusion_matrix(y_test,pred_lr_val))\n",
    "acc2 = accuracy_score(y_test,pred_lr_val)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"reviewtext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabelsSenti_5 = pd.DataFrame(pred_lr_test, columns = [labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_2 = pd.concat([reviewId_Test, testLabelsSenti_5], axis = 1)\n",
    "submission_2.to_csv(\"Submission_5.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:  1.7min finished\n",
      "C:\\Users\\CBPLDEV11\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "C:\\Users\\CBPLDEV11\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning:\n",
      "\n",
      "Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good' 'bad' 'bad' ... 'bad' 'bad' 'excellent']\n",
      "Train_Confusion matrix:\n",
      " [[161   3  41]\n",
      " [ 15 254 145]\n",
      " [ 51 137 451]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6883942766295708"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "# clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\n",
    "\n",
    "clf_cv = GridSearchCV(estimator=LogisticRegression(random_state = 899, tol = 0.001, class_weight='balanced'),\n",
    "            param_grid=param_grid, verbose=True, cv = 10,n_jobs = -1)\n",
    "\n",
    "lr_clf = clf_cv.fit(X_Train_tf, y_train)\n",
    "\n",
    "pred_lr_train=lr_clf.predict(X_Train_tf) # predict on train data\n",
    "pred_lr_val = lr_clf.predict(X_val_tf)\n",
    "\n",
    "pred_lr_test_2 = lr_clf.predict(X_unseen_tf)\n",
    "\n",
    "print(pred_lr_test_2)\n",
    "print(\"Train_Confusion matrix:\\n\", confusion_matrix(y_test,pred_lr_val))\n",
    "acc2 = accuracy_score(y_test,pred_lr_val)\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabelsSenti_6 = pd.DataFrame(pred_lr_test_2, columns = [labels])\n",
    "submission_6 = pd.concat([reviewId_Test, testLabelsSenti_6], axis = 1)\n",
    "submission_6.to_csv(\"Submission_6.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5029, 200), (1258, 200))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_num_words) #Tokenizer is used to tokenize text\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(X_train) #'text to sequences converts the text to a list of indices\n",
    "x_train = pad_sequences(x_train, maxlen=seq_len) #pad_sequences makes every sequence a fixed size list by padding with 0s \n",
    "\n",
    "x_val = tokenizer.texts_to_sequences(X_test) #'text to sequences converts the text to a list of indices\n",
    "x_val = pad_sequences(x_val, maxlen=seq_len) #pad_sequences makes every sequence a fixed size list by padding with 0s \n",
    "\n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3468, 200), (3468, 200))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_test = Tokenizer(num_words=max_num_words) #Tokenizer is used to tokenize text\n",
    "tokenizer_test.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "x_test = tokenizer_test.texts_to_sequences(testData.reviewtext) #'text to sequences converts the text to a list of indices\n",
    "x_test = pad_sequences(x_test, maxlen=seq_len) #pad_sequences makes every sequence a fixed size list by padding with 0s \n",
    "\n",
    "y_test_2 = tokenizer_test.texts_to_sequences(y_test) #'text to sequences converts the text to a list of indices\n",
    "y_test_2= pad_sequences(x_test, maxlen=seq_len)\n",
    "\n",
    "x_test.shape, y_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hotel', 11301), ('room', 10745), ('stay', 6526), ('great', 4765), ('would', 3751), ('get', 3359), ('good', 3201), ('location', 3135), ('night', 3023), ('nice', 2842), ('staff', 2836), ('one', 2522), ('time', 2303), ('go', 2299), ('bed', 2252), ('clean', 2220), ('day', 1987), ('place', 1961), ('walk', 1929), ('service', 1857), ('small', 1698), ('also', 1653), ('area', 1610), ('breakfast', 1599), ('well', 1582), ('restaurant', 1581), ('could', 1520), ('like', 1466), ('floor', 1387), ('make', 1386), ('bathroom', 1383), ('price', 1340), ('take', 1326), ('view', 1323), ('desk', 1307), ('street', 1301), ('find', 1291), ('even', 1278), ('friendly', 1260), ('park', 1249), ('really', 1235), ('comfortable', 1230), ('back', 1227), ('two', 1215), ('check', 1203), ('look', 1201), ('front', 1160), ('helpful', 1157), ('book', 1145), ('little', 1122), ('say', 1108), ('use', 1093), ('car', 1076), ('need', 1072), ('city', 1068), ('free', 1065), ('want', 1060), ('pool', 1025), ('square', 1021), ('block', 999), ('much', 992), ('give', 983), ('next', 982), ('close', 975), ('recommend', 970), ('excellent', 967), ('around', 944), ('new', 928), ('pay', 926), ('san', 908), ('ask', 903), ('right', 895), ('lobby', 895), ('minute', 889), ('call', 884), ('first', 883), ('problem', 879), ('food', 877), ('th', 855), ('come', 853), ('large', 840), ('best', 825), ('away', 816), ('people', 805), ('lot', 790), ('think', 784), ('old', 782), ('door', 778), ('see', 770), ('love', 766), ('thing', 753), ('review', 751), ('tell', 743), ('morning', 734), ('work', 718), ('bar', 715), ('noise', 715), ('francisco', 711), ('union', 706), ('trip', 705)]\n",
      "23138\n"
     ]
    }
   ],
   "source": [
    "#checking counts\n",
    "A=tokenizer.word_counts\n",
    "sorted_by_value = sorted(A.items(), key=lambda kv: kv[1],reverse=True)\n",
    "print(sorted_by_value[0:100])\n",
    "print(len(sorted_by_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hotel', 11301), ('room', 10745), ('stay', 6526), ('great', 4765), ('would', 3751), ('get', 3359), ('good', 3201), ('location', 3135), ('night', 3023), ('nice', 2842), ('staff', 2836), ('one', 2522), ('time', 2303), ('go', 2299), ('bed', 2252), ('clean', 2220), ('day', 1987), ('place', 1961), ('walk', 1929), ('service', 1857), ('small', 1698), ('also', 1653), ('area', 1610), ('breakfast', 1599), ('well', 1582), ('restaurant', 1581), ('could', 1520), ('like', 1466), ('floor', 1387), ('make', 1386), ('bathroom', 1383), ('price', 1340), ('take', 1326), ('view', 1323), ('desk', 1307), ('street', 1301), ('find', 1291), ('even', 1278), ('friendly', 1260), ('park', 1249), ('really', 1235), ('comfortable', 1230), ('back', 1227), ('two', 1215), ('check', 1203), ('look', 1201), ('front', 1160), ('helpful', 1157), ('book', 1145), ('little', 1122), ('say', 1108), ('use', 1093), ('car', 1076), ('need', 1072), ('city', 1068), ('free', 1065), ('want', 1060), ('pool', 1025), ('square', 1021), ('block', 999), ('much', 992), ('give', 983), ('next', 982), ('close', 975), ('recommend', 970), ('excellent', 967), ('around', 944), ('new', 928), ('pay', 926), ('san', 908), ('ask', 903), ('right', 895), ('lobby', 895), ('minute', 889), ('call', 884), ('first', 883), ('problem', 879), ('food', 877), ('th', 855), ('come', 853), ('large', 840), ('best', 825), ('away', 816), ('people', 805), ('lot', 790), ('think', 784), ('old', 782), ('door', 778), ('see', 770), ('love', 766), ('thing', 753), ('review', 751), ('tell', 743), ('morning', 734), ('work', 718), ('bar', 715), ('noise', 715), ('francisco', 711), ('union', 706), ('trip', 705)]\n",
      "23138\n"
     ]
    }
   ],
   "source": [
    "#checking counts\n",
    "A=tokenizer_test.word_counts\n",
    "sorted_by_value = sorted(A.items(), key=lambda kv: kv[1],reverse=True)\n",
    "print(sorted_by_value[0:100])\n",
    "print(len(sorted_by_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23138 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23138 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer_test.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'bad', 'excellent']\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(y_train.unique())\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'excellent' 'good']\n",
      "(array([0, 1, 2]), array([ 898, 1557, 2574], dtype=int64))\n",
      "(array([0, 1, 2]), array([205, 414, 639], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()                  # converts the character array to numeric array. Assigns levels to unique labels.\n",
    "le.fit(y_train)\n",
    "train_labels = le.transform(y_train)\n",
    "val_labels = le.transform(y_test)\n",
    "\n",
    "print(le.classes_)\n",
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(val_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (6287, 1)\n",
      "Shape of trian label tensor: (5029, 3)\n",
      "Shape of validation label tensor: (1258, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "labels_train = to_categorical(np.asarray(train_labels))\n",
    "labels_val = to_categorical(np.asarray(val_labels))\n",
    "\n",
    "print('Shape of data tensor:', y.shape)\n",
    "print('Shape of trian label tensor:', labels_train.shape)\n",
    "print('Shape of validation label tensor:', labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic CNN 1D\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D, Embedding\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words,\n",
    "                    embedding_size,\n",
    "                    input_length=seq_len\n",
    "                    ))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          20000     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 196, 64)           32064     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 196, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 60,771\n",
      "Trainable params: 60,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', #compiling\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...  34   2 174]\n",
      " [  0   0   0 ...  62 163 163]\n",
      " [  0   0   0 ...  41 104   3]\n",
      " ...\n",
      " [  0   0   0 ... 199  85 124]\n",
      " [  0   0   0 ... 112  61  25]\n",
      " [  0   0   0 ...   0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "print(x_val)\n",
    "# print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5029 samples, validate on 1258 samples\n",
      "Epoch 1/5\n",
      "5029/5029 [==============================] - 14s 3ms/step - loss: 0.9960 - acc: 0.5035 - val_loss: 0.9404 - val_acc: 0.5079\n",
      "Epoch 2/5\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.8293 - acc: 0.5870 - val_loss: 0.7807 - val_acc: 0.6097\n",
      "Epoch 3/5\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.7225 - acc: 0.6606 - val_loss: 0.7463 - val_acc: 0.6320\n",
      "Epoch 4/5\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.6645 - acc: 0.6942 - val_loss: 0.7581 - val_acc: 0.6423\n",
      "Epoch 5/5\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.6159 - acc: 0.7200 - val_loss: 0.7564 - val_acc: 0.6455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a925a1320>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, labels_train,  #Fitting\n",
    "          batch_size=64,\n",
    "          epochs=5,\n",
    "          validation_data=(x_val, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258/1258 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9747981503961196, 0.6287758345634267]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00655592, 0.4681948 , 0.5252492 ],\n",
       "       [0.00323995, 0.6587146 , 0.33804545],\n",
       "       [0.02488112, 0.27571857, 0.69940025],\n",
       "       ...,\n",
       "       [0.0042456 , 0.23376922, 0.7619852 ],\n",
       "       [0.5938396 , 0.09765512, 0.30850527],\n",
       "       [0.23890847, 0.3465262 , 0.41456532]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prob=model.predict(x_val) # Checking test probs\n",
    "test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "testUnseen_prob= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "testUnseen_prob_classes = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13167378, 0.24802943, 0.6202968 ],\n",
       "       [0.62646455, 0.13454306, 0.2389924 ],\n",
       "       [0.87972903, 0.03318326, 0.08708771],\n",
       "       ...,\n",
       "       [0.21790917, 0.30754802, 0.4745428 ],\n",
       "       [0.313601  , 0.24600518, 0.44039375],\n",
       "       [0.11607733, 0.5208936 , 0.36302906]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testUnseen_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testUnseen_prob_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "testUnseen_prob_classes = le.inverse_transform(testUnseen_prob_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 2, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#body belongs to which clases\n",
    "test_classes=model.predict_classes(x_val) #predicting test classes\n",
    "test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'bad', 'bad', ..., 'good', 'good', 'excellent'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testUnseen_prob_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes=pd.DataFrame(test_classes)\n",
    "test_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6454689984101749"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes1 = np.argmax(test_prob, axis=1)\n",
    "print(test_classes1.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_classes1,np.argmax(labels_val, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 2, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testclasses_test=model.predict_classes(x_test) #predicting test classes\n",
    "testclasses_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = le.inverse_transform(testclasses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'bad', 'bad', ..., 'good', 'good', 'excellent'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"Sentiment\"\n",
    "\n",
    "testLabelsSenti = pd.DataFrame(test_submission, columns = [labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([reviewId_Test, testLabelsSenti], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"Submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM, Embedding\n",
    "\n",
    "\n",
    "model_lstm = Sequential() # Call Sequential to initialize a network\n",
    "model_lstm.add(Embedding(input_dim = max_num_words, \n",
    "                    input_length = seq_len, \n",
    "                    output_dim = embedding_size)) # Add an embedding layer which represents each unique token as a vector\n",
    "model_lstm.add(LSTM(10, return_sequences=True)) # Add an LSTM layer\n",
    "model_lstm.add(LSTM(10, return_sequences=False))\n",
    "model_lstm.add(Dense(3, activation='softmax')) # Add an ouput layer. Since classification, 3 nodes for 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 200, 100)          20000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200, 10)           4440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 25,313\n",
      "Trainable params: 25,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(optimizer=adam,                  # 'Adam' is a variant of gradient descent technique\n",
    "              loss='categorical_crossentropy', # categorical_crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5029 samples, validate on 1258 samples\n",
      "Epoch 1/6\n",
      "5029/5029 [==============================] - 18s 4ms/step - loss: 1.0087 - acc: 0.5088 - val_loss: 0.9218 - val_acc: 0.5246\n",
      "Epoch 2/6\n",
      "5029/5029 [==============================] - 16s 3ms/step - loss: 0.8566 - acc: 0.5788 - val_loss: 0.8382 - val_acc: 0.6017\n",
      "Epoch 3/6\n",
      "5029/5029 [==============================] - 16s 3ms/step - loss: 0.7784 - acc: 0.6365 - val_loss: 0.7984 - val_acc: 0.6129\n",
      "Epoch 4/6\n",
      "5029/5029 [==============================] - 15s 3ms/step - loss: 0.7328 - acc: 0.6639 - val_loss: 0.7619 - val_acc: 0.6486\n",
      "Epoch 5/6\n",
      "5029/5029 [==============================] - 16s 3ms/step - loss: 0.7037 - acc: 0.6850 - val_loss: 0.7624 - val_acc: 0.6494\n",
      "Epoch 6/6\n",
      "5029/5029 [==============================] - 15s 3ms/step - loss: 0.6854 - acc: 0.6946 - val_loss: 0.7670 - val_acc: 0.6423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a94c7e048>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the Model\n",
    "model_lstm.fit(x_train, labels_train,\n",
    "          batch_size=64,\n",
    "          epochs=6,\n",
    "          validation_data=(x_val, labels_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
